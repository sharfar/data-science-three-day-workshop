{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Saving Models in TF\n",
    "\n",
    "We don't want to retrain a neural network every time we spin up a new server. Instead, we want to load a pretrained model from a file (which could live in Amazon's S3, another cloud storage service, or as a blob in a database). The following code would be written in standard python files, versioned with `git` or some other version control system, and deployed to a powerful machine with a good GPU or cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 16:20:15.347822: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 16:20:21.766058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 5ms/step - loss: 2.4052 - accuracy: 0.2588\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.6284 - accuracy: 0.4033\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.0734 - accuracy: 0.6195\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.6678 - accuracy: 0.7730\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4833 - accuracy: 0.8276\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3950 - accuracy: 0.8454\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3368 - accuracy: 0.8597\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2673 - accuracy: 0.9186\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2039 - accuracy: 0.9525\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1631 - accuracy: 0.9614\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1357 - accuracy: 0.9694\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1257 - accuracy: 0.9721\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0995 - accuracy: 0.9770\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0923 - accuracy: 0.9786\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0971 - accuracy: 0.9784\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0784 - accuracy: 0.9817\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0781 - accuracy: 0.9826\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0821 - accuracy: 0.9813\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0730 - accuracy: 0.9835\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0660 - accuracy: 0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: save_files/mnist-model-generic/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: save_files/mnist-model-generic/assets\n"
     ]
    }
   ],
   "source": [
    "## Simple neural network example.\n",
    "## So far this should all look very familiar.\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = 10 \n",
    "image_size = 784\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_data = training_images.reshape(training_images.shape[0], image_size) \n",
    "test_data = test_images.reshape(test_images.shape[0], image_size)\n",
    "\n",
    "training_labels = to_categorical(training_labels, num_classes)\n",
    "test_labels = to_categorical(test_labels, num_classes)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=512, activation='relu', input_shape=(image_size,)),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    \n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(rate=.3),\n",
    "    \n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(rate=.3),\n",
    "    \n",
    "    Dense(units=num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Note: No validation data. In a go-to-production setting, you'd already be confident this model will generalize\n",
    "# so there's no point in validating it. Instead, use all the available data to train!\n",
    "model.fit(training_data, training_labels, batch_size=128, epochs=20, verbose=True) \n",
    "\n",
    "# You can save the file as an .h5, which is specific to the Keras frontend for TF\n",
    "model.save('save_files/mnist-model.h5', save_format='h5')\n",
    "\n",
    "# You can also save the file in a tensorflow format that is slightly more generic\n",
    "model.save('save_files/mnist-model-generic', save_format='tf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models\n",
    "\n",
    "The result of your training on the GPU is a file. Part of your service deployment is now fetching the latest version of that file and putting it in the right place. Part of your server or application code now has to load the saved model into it's memory and run it. \n",
    "\n",
    "This **does require** a significant degree of integration, specifically your server code now has to be in Python and must depend on Keras. In some cases this is not a problem, in some cases it might require standing up a standalone API server in Python and having your (say) Ruby on Rails webserver make web requests to the Python server, which runs the model and returns the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14336198568344116, 0.975600004196167]\n",
      "[0.14336198568344116, 0.975600004196167]\n"
     ]
    }
   ],
   "source": [
    "# Loading models from save files is pretty easy. \n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "trained_loaded_model = load_model('save_files/mnist-model.h5')\n",
    "tf_trained_loaded_model = load_model('save_files/mnist-model-generic')\n",
    "\n",
    "# Loss, Accuracy\n",
    "# They'll be the same, since it's the same model being restored from two different formats.\n",
    "a = trained_loaded_model.evaluate(test_data, test_labels, verbose=False)\n",
    "print(a)\n",
    "\n",
    "b = tf_trained_loaded_model.evaluate(test_data, test_labels, verbose=False)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Checkpoints While Training\n",
    "\n",
    "Your code or computer could crash for any number of reasons at any time. If you've been training for 10 hours and the server running that training goes down but you haven't persisted the results of your training to the hard drive, then you're going to be very sad. Instead of training with `.fit` and `epochs=999999` we want to ensure that you're periodically saving the model.\n",
    "\n",
    "Keras provides a helpful callback class that can automatically persist the model during the training process based on the results. For example, this callback makes it easy to make a checkpoint of the model every time validation accuracy improves, instead of over a fixed number of epochs. This callback can also be configured to only save the weights, see  the [ModelCheckpoint Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92517, saving model to save_files/model-checkpoint.01-0.29.h5\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.92517 to 0.95417, saving model to save_files/model-checkpoint.02-0.19.h5\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.95417 to 0.95767, saving model to save_files/model-checkpoint.03-0.18.h5\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.95767 to 0.96533, saving model to save_files/model-checkpoint.04-0.15.h5\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.96533 to 0.97083, saving model to save_files/model-checkpoint.05-0.13.h5\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.97083\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.97083\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.97083 to 0.97117, saving model to save_files/model-checkpoint.08-0.14.h5\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.97117 to 0.97450, saving model to save_files/model-checkpoint.09-0.13.h5\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.97450 to 0.97500, saving model to save_files/model-checkpoint.10-0.13.h5\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.97500\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.97500\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.97500\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.97500\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.97500\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.97500\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.97500\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.97500\n",
      "\n",
      "Epoch 19: val_accuracy improved from 0.97500 to 0.97833, saving model to save_files/model-checkpoint.19-0.11.h5\n",
      "\n",
      "Epoch 20: val_accuracy improved from 0.97833 to 0.98000, saving model to save_files/model-checkpoint.20-0.12.h5\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.98000\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.98000\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.98000\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.98000\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.98000\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.98000\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.98000\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.98000\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.98000\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.98000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab41e57190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# This string uses the same format as Python's f-strings\n",
    "filename_format = 'save_files/model-checkpoint.{epoch:02d}-{val_loss:.2f}.h5'\n",
    "\n",
    "model_checkpointer = ModelCheckpoint(\n",
    "    filename_format,\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1, \n",
    "    save_best_only=True,     # If True, the checkpoint will be replaced every time the model improves on val_accuracy.\n",
    "    save_weights_only=False, # If True the saved files will be the weights only, not the whole model.\n",
    "    mode='auto', \n",
    "    period=1 # If larger, the checkpointer will only run every n epochs.\n",
    ")\n",
    "\n",
    "fresh_model = Sequential([\n",
    "    Dense(units=512, activation='relu', input_shape=(image_size,)),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    \n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(rate=.3),\n",
    "    \n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(rate=.3),\n",
    "    \n",
    "    Dense(units=num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "fresh_model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "fresh_model.fit(\n",
    "    training_data, \n",
    "    training_labels, \n",
    "    batch_size=128, \n",
    "    epochs=30, \n",
    "    verbose=False, \n",
    "    validation_split=.1,\n",
    "    callbacks=[model_checkpointer] # Here's our checkpointer!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
